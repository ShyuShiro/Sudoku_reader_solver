{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Sudoku reader: https://www.youtube.com/watch?v=qOXDoYUgNlU&t=1505s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biggest_contour(contours):\n",
    "    '''\n",
    "    Loop through every contour to find the one with largest area __that is a square__\n",
    "    \n",
    "    Utilizing max(contour) will return the points that create the largest contour ... but not the corners\n",
    "    \n",
    "    Utilizing cv2.approxPolyDP(img,epsilon,closed_fig=True)\n",
    "        - We are returned the verticies of a polygon\n",
    "        - If len(approxPolyDP) == 4 --- it is a square object\n",
    "    '''\n",
    "    max_area = 0\n",
    "    biggest = np.array([])\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i) #Compute area of each contour\n",
    "        if area > 50:\n",
    "            peri = cv2.arcLength(i,True) #Compute perimeter for better accuracy in next function's Epsilon arg\n",
    "            approx = cv2.approxPolyDP(i,0.02*peri,True) #Find the corners of a polygon\n",
    "            if area > max_area and len(approx) == 4: #If there are exactly 4 points .. its a square! --> we're interested\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "    return biggest,max_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_corners(polygon):\n",
    "    '''\n",
    "    Returns the 4 corners of a contour as [top,left,right,bottom]\n",
    "    '''\n",
    "    polygon = polygon.reshape((4,2))\n",
    "    new_array = np.zeros((4,2),dtype=np.int32)\n",
    "    added = polygon.sum(1) #Result converts (4,2) to (4,1)\n",
    "    \n",
    "    #Top corner will be located where the sum of (x,y) pairs is largest\n",
    "    new_array[0] = polygon[np.argmax(added)]\n",
    "    \n",
    "    #Bottom corner is where they sum to the smallest\n",
    "    new_array[3] = polygon[np.argmin(added)]\n",
    "    \n",
    "    diff = np.diff(polygon,axis=1) #This time .. subtract x-y\n",
    "    \n",
    "    #Left corner is where the sum is largest\n",
    "    new_array[1] = polygon[np.argmax(diff)]\n",
    "    \n",
    "    #Right corner is where the sum is smallest\n",
    "    new_array[2] = polygon[np.argmin(diff)]\n",
    "    \n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box(img):\n",
    "    '''\n",
    "    Covert grid image into 81 boxes\n",
    "    '''\n",
    "    rows = np.vsplit(img,9) #(row by y)*9 entries\n",
    "    boxes = []\n",
    "    for r in rows:\n",
    "        cols = np.hsplit(r,9) #split each (row by y) into (row by col)*9\n",
    "        for c in cols:\n",
    "            boxes.append(c) #Append to list\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_boxes(boxes):\n",
    "    '''\n",
    "    Optional function to display the individual box images\n",
    "    '''\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig,ax = plt.subplots(9,9)\n",
    "\n",
    "    for i,j in enumerate(boxes):\n",
    "        plt.subplot(9,9,i+1)\n",
    "        plt.imshow(j,cmap='gray', vmin=0, vmax=255)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def disp(box,resize=False,save=False,name=\"\"):\n",
    "    if resize:\n",
    "        x,y = box.shape\n",
    "        #Preprocessing\n",
    "        box = cv2.resize(img[margin:y-margin,margin:x-margin],(28,28)) #Crop & shape to the input size of the trained model\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(box,cmap='gray', vmin=0, vmax=255)\n",
    "    plt.axis(\"off\")\n",
    "    if save:\n",
    "        plt.savefig(name)    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(img):\n",
    "    data = []\n",
    "    for img in boxes:\n",
    "        data.append(np.resize(img,(28,28))) #Apply resize + Antialias this time\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(boxes,model):\n",
    "    predictions = []\n",
    "    margin = 9 #Define some arbitrary amount of pixels to pad off the edges of the images\n",
    "    for img in boxes:\n",
    "        x,y = img.shape\n",
    "        #Preprocessing\n",
    "        image = cv2.resize(img[margin:y-margin,margin:x-margin],(28,28)) #Crop & shape to the input size of the trained model\n",
    "        image = image/255 #Just to keep things in [0,1] instead of [0,255] range\n",
    "        image = np.reshape(image,(1,28,28,1)) #Reshape to appropriate dimension of the model\n",
    "        image = -image #Invert color scheme because the MNIST dataset was black background white numbers (this is white background black numbers)\n",
    "        #Predict\n",
    "        pred = model.predict(image)\n",
    "        #Grab necessary information\n",
    "        class_id = np.argmax(pred)\n",
    "        confidence = np.amax(pred)\n",
    "        predictions.append([class_id,confidence])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model=\"my_model.h5\"):\n",
    "    '''\n",
    "    Define a function to load the model ... \n",
    "    I think this is to prevent some issues with tf keeping the model in memory otherwise\n",
    "    '''\n",
    "    m = tf.keras.models.load_model(model)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 682912578058118358\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6959755424\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15914469061402422057\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070, pci bus id: 0000:2b:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Load image\n",
    "#original = cv2.imread(\"Sudoku1_rotated.png\")\n",
    "original = cv2.imread(\"Sudoku3.png\")\n",
    "y,x,_ = original.shape\n",
    "\n",
    "#Set parameter `im_size` to the larger of x or y\n",
    "if x > y:\n",
    "    im_size = x\n",
    "else:\n",
    "    im_size = y\n",
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \n",
    "    \n",
    "\n",
    "good = True\n",
    "\n",
    "while good:\n",
    "    #Show image\n",
    "    #cv2.imshow(\"Original\",original) #Display original image\n",
    "\n",
    "    #2) Convert to gray scale\n",
    "    gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #3) Find contours\n",
    "    edged = cv2.Canny(gray, 30, 200)\n",
    "    contours, hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    contour_image = original.copy() #Copy the original image\n",
    "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)  #Draw on \"contour_image\" the \"contours\" (-1 = all contours) \n",
    "                                                                   #with color \"(0,255,0)\" (BGR) and thinkness of 2\n",
    "    \n",
    "    #cv2.imshow('Contours', contour_image) #Display the contours\n",
    "    \n",
    "    #4a) (Optional) plotting the largest contour\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    c = c.reshape(len(c),2) #Converting (rows of pts,1,[y,x]) to (rows of pts,[y,x])\n",
    "\n",
    "    square = original.copy()\n",
    "    # draw the biggest contour (c) in magenta\n",
    "    cv2.drawContours(square,[c],0,(175,0,150),2)\n",
    "\n",
    "    #4b) Find the largest contour --- this will likely be the sudoku square\n",
    "    dots = original.copy()\n",
    "    biggest,_ = compute_biggest_contour(contours)\n",
    "    for i in biggest:\n",
    "        cv2.circle(dots, (i[0][0],i[0][1]), radius=10, color=(0, 0, 255), thickness=-1) #Testing to see that my function plots things correctly (had to trial & error it)    \n",
    "    \n",
    "    #5) Warp the perspective so the grid is flat\n",
    "    biggest = reorder_corners(biggest)\n",
    "    pt1 = np.array(biggest, dtype='float32')\n",
    "    pt2 = np.float32([[y,x],[0,x],[y,0],[0,0] ])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pt1,pt2)\n",
    "\n",
    "    warped = cv2.warpPerspective(original,M,(y-y%9,x-x%9),flags=cv2.INTER_LINEAR)\n",
    "    warped = cv2.cvtColor(warped,cv2.COLOR_BGR2GRAY) #Convert the warped image to gray scale\n",
    "    \n",
    "    #6) Clean up the grid\n",
    "    thresh = cv2.adaptiveThreshold(warped,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,\n",
    "                                   349, #Block size (how many neighbors define an area) -- larger = less noise\n",
    "                                   30) #C --- the value subtracted from everything to determine if it is above a threshold #\n",
    "    \n",
    "    #7) Split grid into 81 individual images\n",
    "    boxes = box(thresh)\n",
    "    #display_boxes(boxes) #Display the boxes as images (optional)\n",
    "    \n",
    "    #8) Load images into Tensorflow model predict\n",
    "    model = load_model('my_model_4Conv_dropout_18ep.h5') #Load in the trained model\n",
    "    predictions = model_predict(boxes,model)\n",
    "    \n",
    "    #Predict on boxes\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Row 1\",np.hstack([original,contour_image,square,dots])) #Display everything\n",
    "    cv2.imshow(\"Row 2\",np.hstack([warped,thresh])) #Display everything\n",
    "    \n",
    "    #Block to allow breakage of code without Ctrl+C\n",
    "    if cv2.waitKey(0)==27: #code 27 = ESC key\n",
    "        good = False\n",
    "cv2.destroyAllWindows() #Close all windows generated by cv2 commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save individual cell images to run on sudoku model..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 0\n",
    "for img in boxes:\n",
    "    #Preprocessing\n",
    "    disp(img,resize=True,save=True,name=str(i)+\".jpg\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 87 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002105B422EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.12770656, 0.10492215, 0.08559685, 0.16831276, 0.10244622,\n",
       "         0.07253657, 0.12891746, 0.11721693, 0.09234459]], dtype=float32),\n",
       " 4,\n",
       " 0.16831276)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model2 = load_model('my_model_dropout_22ep.h5') #Load in the trained model\n",
    "margin = 9 #Define some arbitrary amount of pixels to pad off the edges of the images\n",
    "for img in boxes:\n",
    "    #Preprocessing\n",
    "    image = cv2.resize(img[margin:y-margin,margin:x-margin],(28,28)) #Crop & shape to the input size of the trained model\n",
    "    image = image/255 #Just to keep things in [0,1] instead of [0,255] range\n",
    "    image = -image #Invert colors\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    image = np.reshape(image,(1,28,28,1)) #Reshape to appropriate dimension of the model\n",
    "    #Predict\n",
    "    pred = model2.predict(image)\n",
    "    #Grab necessary information\n",
    "    class_id = np.argmax(pred) + 1 #Add 1 to adjust for class id being [0,8] instead of [1,9]\n",
    "    confidence = np.amax(pred)\n",
    "    break\n",
    "pred,class_id,confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAADnCAYAAAD4ryiSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEHklEQVR4nO3d204iQRRAUZj4/7/MvO0wJsqgTV2atV5NVDDZOVXVWNfb7XYBuFwulz+zfwFgHYIARBCACAIQQQDy8eDrjiDgfK5ffcGEAEQQgAgCEEEAIghABAGIIAARBCCCAEQQgAgCEEEAIghABAGIIAARBCCCAEQQgAgCEEEAIghABAGIIAARBCCCAEQQgAgCEEEA8uiyVxZ1vX55X+dhbjd3/b4bEwIQQQBiybCYEUuB//XM72J5cQ4mBCCCAEQQgNhDmGClfYKjfPea7C/sw4QARBCAWDIMcMYlwjMsJ/ZhQgAiCEAEAYg9hBeYsWfwirX4iNfx+WfYU5jLhABEEIBYMmxk9Dj93c9796PUszIhABEEIIIAxB7CQd5tTf15f+Go13//fRxBjmdCACIIQAQBiD2Ehb37GtpjzeOZEIAIAhBLhsXsOha/6hiSsUwIQAQBiCAAEQQgggBEEIAIAhBBACIIQAQBiCAAEQQgggDEpx1Z1q6f/NyZCQGIIAARBCD2EA5yv979zX8LclEJM5kQgAgCEEEAYg9hYTtdVOK/LJ+DCQGIIAC5PhhD151RNzJinB69nHjVa1p5WXQiX/7xTAhABAGIIABx7DjAiItQHftxBBMCEEEAYskwwVGfjNyVo8V1mRCACAIQQQAiCEAEAYggAHHsOME7HjWyBxMCEEEAIghA7CEMYM/gX9+9Hx5rnsuEAEQQgAgCEHsIBxm9TzBjrT3iNbrsdi4TAhBBAOKilh864+Urv+H92IqLWoDHBAGIIABx7LiYXdfJMy6j2fW9WpkJAYggABEEIIIARBCACAIQjy4/4RVHae9wdOax5uV4dBl4TBCACAIQjy7zciMea+YYJgQgggBEEIAIAhBBACIIQBw7TuAxW1ZlQgAiCEAEAYggABEEIIIAxLHjBPef9nMEyUpMCEAEAYglw2TvcF+hf4iyDxMCEEEAIghA7CE84X59b13MGZkQgAgCEEEAYg9hMR5r/n/en+OZEIAIAhBLhh8acV/hTo81O4Y9BxMCEEEAIghArg/WpesuWhc2Yj09ez9hxp7B7Nd8Il/+8UwIQAQBiGPHTf1mZN/lU5uWCOOZEIAIAhBBAOLYcYKV1+2z2TcYwrEj8JggAHHsOMEux36vYlmwLhMCEEEAIghA7CFM9sx6etf9BnsG+zAhABEEIIIAxB7CRkbvN1j7vx8TAhBBAGLJcFLGfX7ChABEEIAIAhBBACIIQAQBiCAAEQQgggBEEIAIAhBBACIIQAQBiCAAEQQgggBEEIAIAhBBACIIQAQBiCAAEQQgggBEEIAIAhBBACIIQAQBiCAAEQQgggBEEIAIAhBBACIIQAQBiCAAEQQgggBEEIB8PPj6dchvASzBhABEEIAIAhBBACIIQAQByF+M17v4IUoCiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp(img[margin:y-margin,margin:x-margin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 0.1289336],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1339564],\n",
       " [0, 0.1338971],\n",
       " [0, 0.13167329],\n",
       " [0, 0.13383338],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12907667],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12955815],\n",
       " [0, 0.13389851],\n",
       " [7, 0.12934938],\n",
       " [0, 0.1338971],\n",
       " [0, 0.12964538],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1311944],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12969784],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12853588],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12957025],\n",
       " [0, 0.1338971],\n",
       " [0, 0.13384467],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12841332],\n",
       " [0, 0.13384631],\n",
       " [0, 0.12936975],\n",
       " [0, 0.1338971],\n",
       " [0, 0.13080052],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12943645],\n",
       " [0, 0.1338971],\n",
       " [7, 0.13064697],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12912144],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12779078],\n",
       " [0, 0.1338971],\n",
       " [0, 0.12965891],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12952206],\n",
       " [0, 0.1338971],\n",
       " [0, 0.13003887],\n",
       " [0, 0.13398482],\n",
       " [7, 0.1300187],\n",
       " [0, 0.1338971],\n",
       " [7, 0.1295403],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12932876],\n",
       " [0, 0.13418531],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [0, 0.13001795],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12989138],\n",
       " [0, 0.1338971],\n",
       " [7, 0.1281039],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [7, 0.13028961],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12996887],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12890905],\n",
       " [0, 0.1338971],\n",
       " [7, 0.13038413],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12885657],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [7, 0.12967598],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338971],\n",
       " [0, 0.1338379],\n",
       " [7, 0.128496]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 84]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [ 64]\n",
      "   [194]\n",
      "   [ 84]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 20]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [191]\n",
      "   [ 75]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [130]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [191]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [ 30]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [191]\n",
      "   [191]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  2]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [157]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [ 82]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [191]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [ 82]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [191]\n",
      "   [  0]\n",
      "   [ 52]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [ 48]\n",
      "   [  0]\n",
      "   [209]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [ 64]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [207]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [ 84]\n",
      "   [255]\n",
      "   [255]\n",
      "   [166]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [157]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [ 64]\n",
      "   [  0]\n",
      "   [ 82]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [191]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 20]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [155]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [155]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [ 16]\n",
      "   [  0]\n",
      "   [ 82]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [155]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [207]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [ 64]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [ 64]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [ 61]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [221]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [191]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 20]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]\n",
      "\n",
      "  [[ 27]\n",
      "   [  0]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]\n",
      "   [255]]]] (1, 28, 28, 1)\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential_1/conv2d/Conv2D (defined at <ipython-input-9-4f57fd35a614>:6) ]] [Op:__inference_predict_function_867]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4f57fd35a614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential_1/conv2d/Conv2D (defined at <ipython-input-9-4f57fd35a614>:6) ]] [Op:__inference_predict_function_867]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "a = cv2.resize(boxes[0],(28,28))\n",
    "a = a.reshape(1,28,28,1)\n",
    "\n",
    "print(a,a.shape)\n",
    "\n",
    "predictions = model.predict(a)\n",
    "\n",
    "class_idx = np.argmax(predictions)\n",
    "acc = np.amax(predictions)\n",
    "\n",
    "print(predictions)\n",
    "print(class_idx,acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display one of the boxes as resized image & run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential_1/conv2d/Conv2D (defined at <ipython-input-11-3c3384412829>:10) ]] [Op:__inference_predict_function_866]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3c3384412829>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcrop_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcrop_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Reshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mguess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential_1/conv2d/Conv2D (defined at <ipython-input-11-3c3384412829>:10) ]] [Op:__inference_predict_function_866]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "img_num = 40\n",
    "x,y = boxes[img_num].shape\n",
    "margin = 9\n",
    "crop_img = boxes[img_num][margin:y-margin,margin:x-margin]\n",
    "disp(crop_img,resize=True)\n",
    "\n",
    "#Now try and feed to predictor\n",
    "crop_img = cv2.resize(crop_img.shape,(28,28)) #Resize\n",
    "crop_img = np.reshape(crop_img,(1,28,28,1)) #Reshape\n",
    "guess = model.predict(crop_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
